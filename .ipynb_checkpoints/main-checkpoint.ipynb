{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import ndjson\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/simplified_ndjson/aircraft carrier.ndjson') as f:\n",
    "#     data = ndjson.load(f)\n",
    "#     print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 total classes\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/simplified_ndjson/')), 'total classes')\n",
    "# for file in os.listdir('data/simplified/'):\n",
    "#     print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# print(data[9])\n",
    "good_class_list = ['airplane.ndjson', 'monkey.ndjson', 'axe.ndjson', 'rhinoceros.ndjson', 'bear.ndjson', \n",
    "                   'windmill.ndjson', 'bicycle.ndjson', 'car.ndjson', 'clock.ndjson', 'wine bottle.ndjson',\n",
    "                  'cruise ship.ndjson', 'eye.ndjson', 'giraffe.ndjson', 'The Eiffel Tower.ndjson',\n",
    "                  'house.ndjson', 'ice cream.ndjson', 'octopus.ndjson', 'panda.ndjson', \n",
    "                   'pizza.ndjson', 'smiley face.ndjson']\n",
    "print(len(good_class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data so it is easily usable in pytorch\n",
    "\n",
    "# for file in os.listdir('data/simplified_ndjson/'):\n",
    "#     added = 0\n",
    "#     if file in good_class_list:\n",
    "#         with open('data/simplified_ndjson/' + file) as f:\n",
    "#             data = ndjson.load(f)\n",
    "#             print(file, 'with', len(data), 'items')\n",
    "#             for idx, data_point in enumerate(data):\n",
    "#                 if added >= 10000:\n",
    "#                     break\n",
    "#                 root = 'data/simplified_tiny/' + data_point['word'] + '/'\n",
    "#                 if not os.path.exists(root):\n",
    "#                     os.mkdir(root)\n",
    "#                 if data_point['recognized']:\n",
    "#                     added += 1\n",
    "#                     torch.save(data_point['drawing'], root + str(idx) + '.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_strokes(strokes):\n",
    "#     x_array = []\n",
    "#     y_array = []\n",
    "#     for i in range(len(strokes)):\n",
    "#         x_array += strokes[i][0]\n",
    "#         y_array += strokes[i][1]\n",
    "        \n",
    "#     return [x_array, y_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_from_strokes(strokes):\n",
    "#     base_img = np.ones((256, 256))\n",
    "#     for stroke in strokes:\n",
    "#         for i in range(len(stroke[0]) - 1):\n",
    "#             pt1 = (stroke[0][i], stroke[1][i])\n",
    "#             pt2 = (stroke[0][i + 1], stroke[1][i + 1])\n",
    "#             cv2.line(base_img, pt1, pt2, color=0, thickness=4, lineType=cv2.LINE_AA)\n",
    "#     return base_img\n",
    "\n",
    "# def draw_from_strokes2(strokes):\n",
    "#     val = 256\n",
    "#     plt.figure(figsize=(val/96, val/96), dpi=96)\n",
    "#     plt.axis('off')\n",
    "#     plt.xlim(0,255)\n",
    "#     plt.ylim(0,255)\n",
    "#     for stroke in strokes:\n",
    "#         for i in range(len(stroke[0]) - 1):\n",
    "#             pt1 = (stroke[0][i], stroke[1][i])\n",
    "#             pt2 = (stroke[0][i + 1], stroke[1][i + 1])\n",
    "#             x = (stroke[0][i], stroke[0][i + 1])\n",
    "#             y = (255 - stroke[1][i], 255 - stroke[1][i + 1])\n",
    "#             plt.plot(x, y, color='black', linewidth=4, marker=None)\n",
    "#     plt.savefig(\"my_img.png\")\n",
    "#     plt.close()\n",
    "#     img = np.array(Image.open(\"my_img.png\").convert('L'))\n",
    "#     return img / 255.\n",
    "    \n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data[1]['drawing']\n",
    "# print(test)\n",
    "# img1 = draw_from_strokes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(500/96, 500/96), dpi=96)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img1, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2 = draw_from_strokes2(test)\n",
    "# plt.figure(figsize=(500/96, 500/96), dpi=96)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img2, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = draw_from_strokes2(test)\n",
    "# img2 = draw_from_strokes(test)\n",
    "\n",
    "# plt.figure(figsize=(500/96, 500/96), dpi=96)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img1-img2, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1132543087005615\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose([transforms.RandomAffine(degrees=0,\n",
    "#                                                     translate=(0.1, 0.1)),\n",
    "#                                transforms.ToTensor()])\n",
    "start = time.time()\n",
    "dataset = Quickdraw_traindata('data/simplified_tiny/')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset, \"data/quickdraw_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# dataset = torch.load('data/quickdraw_dataset.pt')\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256]) torch.Size([32, 1, 256, 256]) torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "print(datapoint[0].shape, datapoint[1].shape, datapoint[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(datapoint[2].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "with torch.no_grad():\n",
    "    disc = nn.DataParallel(SA_Discriminator(imsize=256, F=64)).to(0)\n",
    "    disc.load_state_dict(torch.load('models/quickdraw_sagan/disc_10.pt'))\n",
    "    disc.eval()\n",
    "    gen = nn.DataParallel(SA_Generator(imsize=256, F=64)).to(0)\n",
    "    gen.load_state_dict(torch.load('models/quickdraw_sagan/gen_10.pt'))\n",
    "    gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "# with torch.no_grad():\n",
    "    \n",
    "#     classes_onehot = torch.FloatTensor(32, 20).to(0)\n",
    "#     for i in range(1):\n",
    "#         batch = next(test)\n",
    "#         full_imgs, cut_imgs, classes = batch[0].to(0).float(), batch[1].to(0).float(), batch[2].to(0).float()\n",
    "# #         classes = classes.view(-1, 1)\n",
    "#         print(classes)\n",
    "#         classes_onehot.zero_()\n",
    "#         classes_onehot.scatter_(1, classes, 1)\n",
    "#         print(classes_onehot[0])\n",
    "#         z = torch.rand(size=(len(full_imgs), 100))\n",
    "#         generated = gen(cut_imgs, classes, z)\n",
    "\n",
    "#         predictions = disc(full_imgs, classes)\n",
    "#         fake_predictions = disc(generated, classes)\n",
    "\n",
    "\n",
    "#     #     print(predictions)\n",
    "#     #     print(fake_predictions)\n",
    "#         print(real_accuracy(predictions))\n",
    "#         print(fake_accuracy(fake_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(4, 4, figsize=(20,10))\n",
    "# start =  time.time()\n",
    "# for x in range(4):\n",
    "#     for y in range(4):\n",
    "#         img = datapoint[0][4 * x + y].view(256,256)\n",
    "#         axes[x, y].imshow(img, cmap='Greys')\n",
    "#         axes[x, y].axis('off')\n",
    "# end = time.time()\n",
    "# plt.show()\n",
    "# print(\"Time Elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(4, 4, figsize=(20,10))\n",
    "# start =  time.time()\n",
    "# for x in range(4):\n",
    "#     for y in range(4):\n",
    "#         img = datapoint[1][4 * x + y].view(256,256)\n",
    "#         axes[x, y].imshow(img, cmap='Greys')\n",
    "#         axes[x, y].axis('off')\n",
    "# end = time.time()\n",
    "# plt.show()\n",
    "# print(\"Time Elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0022], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0040], device='cuda:0', requires_grad=True)\n",
      "1 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([0.0015], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0037], device='cuda:0', requires_grad=True)\n",
      "2 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0002], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0018], device='cuda:0', requires_grad=True)\n",
      "3 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0001], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0011], device='cuda:0', requires_grad=True)\n",
      "4 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([7.1123e-06], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.7868e-06], device='cuda:0', requires_grad=True)\n",
      "5 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0008], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0035], device='cuda:0', requires_grad=True)\n",
      "6 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0024], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0010], device='cuda:0', requires_grad=True)\n",
      "7 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0026], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0024], device='cuda:0', requires_grad=True)\n",
      "8 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0018], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0036], device='cuda:0', requires_grad=True)\n",
      "9 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0030], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0023], device='cuda:0', requires_grad=True)\n",
      "10 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0022], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0041], device='cuda:0', requires_grad=True)\n",
      "11 -------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/quickdraw_sagan/gen_12.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ade366ed8ef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSA_Generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/quickdraw_sagan/gen_{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#     gen.apply(test_dropout)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/quickdraw_sagan/gen_12.pt'"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "with torch.no_grad():\n",
    "    real_imgs, cut_imgs, labels = next(iter(dataloader))\n",
    "    labels = labels.float()\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,3))\n",
    "    for i in range(5):\n",
    "        axes[i].imshow(real_imgs[i].view(256,256), cmap=\"Greys\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "    gen = nn.DataParallel(SA_Generator(imsize=256, F=64)).to(0)\n",
    "    disc = nn.DataParallel(SA_Discriminator(imsize=256, F=64)).to(0)\n",
    "    for i in range(1, 100, 1):\n",
    "        gen.load_state_dict(torch.load('models/quickdraw_sagan/gen_{}.pt'.format(i)))\n",
    "        gen.eval()\n",
    "    #     gen.apply(test_dropout)\n",
    "        print(gen.module.attention1.gamma)\n",
    "        print(gen.module.attention2.gamma)\n",
    "#         z = torch.rand(size=(len(real_imgs), 100))\n",
    "#         generated = gen(cut_imgs, labels, z)\n",
    "#         fig, axes = plt.subplots(2, 5, figsize=(10,3))\n",
    "#         for y in range(5):\n",
    "#             axes[0, y].imshow(cut_imgs[y].view(256,256).cpu().detach(), cmap=\"Greys\")\n",
    "#             axes[0, y].axis('off')\n",
    "#             axes[1, y].imshow(class_imgs[0 + y].view(28,28), cmap=\"Greys\")\n",
    "        #     axes[1, y].axis('off')\n",
    "#             axes[1, y].imshow(generated[y].cpu().detach().view(256,256), cmap=\"Greys\")\n",
    "#             axes[1, y].axis('off')\n",
    "    #         axes[1, y].set_title(labels[y].item())\n",
    "    #     print(disc(generated, labels).mean())\n",
    "        print(str(i) + ' -------------------------------------------')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
