{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import ndjson\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/simplified_ndjson/aircraft carrier.ndjson') as f:\n",
    "#     data = ndjson.load(f)\n",
    "#     print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 total classes\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/simplified_ndjson/')), 'total classes')\n",
    "# for file in os.listdir('data/simplified/'):\n",
    "#     print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# print(data[9])\n",
    "good_class_list = ['airplane.ndjson', 'monkey.ndjson', 'axe.ndjson', 'rhinoceros.ndjson', 'bear.ndjson', \n",
    "                   'windmill.ndjson', 'bicycle.ndjson', 'car.ndjson', 'clock.ndjson', 'wine bottle.ndjson',\n",
    "                  'cruise ship.ndjson', 'eye.ndjson', 'giraffe.ndjson', 'The Eiffel Tower.ndjson',\n",
    "                  'house.ndjson', 'ice cream.ndjson', 'octopus.ndjson', 'panda.ndjson', \n",
    "                   'pizza.ndjson', 'smiley face.ndjson']\n",
    "print(len(good_class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data so it is easily usable in pytorch\n",
    "\n",
    "# for file in os.listdir('data/simplified_ndjson/'):\n",
    "#     added = 0\n",
    "#     if file in good_class_list:\n",
    "#         with open('data/simplified_ndjson/' + file) as f:\n",
    "#             data = ndjson.load(f)\n",
    "#             print(file, 'with', len(data), 'items')\n",
    "#             for idx, data_point in enumerate(data):\n",
    "#                 if added >= 10000:\n",
    "#                     break\n",
    "#                 root = 'data/simplified_tiny/' + data_point['word'] + '/'\n",
    "#                 if not os.path.exists(root):\n",
    "#                     os.mkdir(root)\n",
    "#                 if data_point['recognized']:\n",
    "#                     added += 1\n",
    "#                     torch.save(data_point['drawing'], root + str(idx) + '.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_strokes(strokes):\n",
    "#     x_array = []\n",
    "#     y_array = []\n",
    "#     for i in range(len(strokes)):\n",
    "#         x_array += strokes[i][0]\n",
    "#         y_array += strokes[i][1]\n",
    "        \n",
    "#     return [x_array, y_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_from_strokes(strokes):\n",
    "#     base_img = np.ones((256, 256))\n",
    "#     for stroke in strokes:\n",
    "#         for i in range(len(stroke[0]) - 1):\n",
    "#             pt1 = (stroke[0][i], stroke[1][i])\n",
    "#             pt2 = (stroke[0][i + 1], stroke[1][i + 1])\n",
    "#             cv2.line(base_img, pt1, pt2, color=0, thickness=4, lineType=cv2.LINE_AA)\n",
    "#     return base_img\n",
    "\n",
    "# def draw_from_strokes2(strokes):\n",
    "#     val = 256\n",
    "#     plt.figure(figsize=(val/96, val/96), dpi=96)\n",
    "#     plt.axis('off')\n",
    "#     plt.xlim(0,255)\n",
    "#     plt.ylim(0,255)\n",
    "#     for stroke in strokes:\n",
    "#         for i in range(len(stroke[0]) - 1):\n",
    "#             pt1 = (stroke[0][i], stroke[1][i])\n",
    "#             pt2 = (stroke[0][i + 1], stroke[1][i + 1])\n",
    "#             x = (stroke[0][i], stroke[0][i + 1])\n",
    "#             y = (255 - stroke[1][i], 255 - stroke[1][i + 1])\n",
    "#             plt.plot(x, y, color='black', linewidth=4, marker=None)\n",
    "#     plt.savefig(\"my_img.png\")\n",
    "#     plt.close()\n",
    "#     img = np.array(Image.open(\"my_img.png\").convert('L'))\n",
    "#     return img / 255.\n",
    "    \n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data[1]['drawing']\n",
    "# print(test)\n",
    "# img1 = draw_from_strokes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(500/96, 500/96), dpi=96)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img1, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2 = draw_from_strokes2(test)\n",
    "# plt.figure(figsize=(500/96, 500/96), dpi=96)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img2, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = draw_from_strokes2(test)\n",
    "# img2 = draw_from_strokes(test)\n",
    "\n",
    "# plt.figure(figsize=(500/96, 500/96), dpi=96)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img1-img2, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1132543087005615\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose([transforms.RandomAffine(degrees=0,\n",
    "#                                                     translate=(0.1, 0.1)),\n",
    "#                                transforms.ToTensor()])\n",
    "start = time.time()\n",
    "dataset = Quickdraw_traindata('data/simplified_tiny/')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset, \"data/quickdraw_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# dataset = torch.load('data/quickdraw_dataset.pt')\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256]) torch.Size([32, 1, 256, 256]) torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "print(datapoint[0].shape, datapoint[1].shape, datapoint[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(datapoint[2].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "with torch.no_grad():\n",
    "    disc = nn.DataParallel(SA_Discriminator(imsize=256, F=64)).to(0)\n",
    "    disc.load_state_dict(torch.load('models/quickdraw_sagan/disc_10.pt'))\n",
    "    disc.eval()\n",
    "    gen = nn.DataParallel(SA_Generator(imsize=256, F=64)).to(0)\n",
    "    gen.load_state_dict(torch.load('models/quickdraw_sagan/gen_10.pt'))\n",
    "    gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "# with torch.no_grad():\n",
    "    \n",
    "#     classes_onehot = torch.FloatTensor(32, 20).to(0)\n",
    "#     for i in range(1):\n",
    "#         batch = next(test)\n",
    "#         full_imgs, cut_imgs, classes = batch[0].to(0).float(), batch[1].to(0).float(), batch[2].to(0).float()\n",
    "# #         classes = classes.view(-1, 1)\n",
    "#         print(classes)\n",
    "#         classes_onehot.zero_()\n",
    "#         classes_onehot.scatter_(1, classes, 1)\n",
    "#         print(classes_onehot[0])\n",
    "#         z = torch.rand(size=(len(full_imgs), 100))\n",
    "#         generated = gen(cut_imgs, classes, z)\n",
    "\n",
    "#         predictions = disc(full_imgs, classes)\n",
    "#         fake_predictions = disc(generated, classes)\n",
    "\n",
    "\n",
    "#     #     print(predictions)\n",
    "#     #     print(fake_predictions)\n",
    "#         print(real_accuracy(predictions))\n",
    "#         print(fake_accuracy(fake_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(4, 4, figsize=(20,10))\n",
    "# start =  time.time()\n",
    "# for x in range(4):\n",
    "#     for y in range(4):\n",
    "#         img = datapoint[0][4 * x + y].view(256,256)\n",
    "#         axes[x, y].imshow(img, cmap='Greys')\n",
    "#         axes[x, y].axis('off')\n",
    "# end = time.time()\n",
    "# plt.show()\n",
    "# print(\"Time Elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(4, 4, figsize=(20,10))\n",
    "# start =  time.time()\n",
    "# for x in range(4):\n",
    "#     for y in range(4):\n",
    "#         img = datapoint[1][4 * x + y].view(256,256)\n",
    "#         axes[x, y].imshow(img, cmap='Greys')\n",
    "#         axes[x, y].axis('off')\n",
    "# end = time.time()\n",
    "# plt.show()\n",
    "# print(\"Time Elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0022], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0040], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0178], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0020], device='cuda:0', requires_grad=True)\n",
      "1 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([0.0015], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0037], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0247], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0164], device='cuda:0', requires_grad=True)\n",
      "2 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0002], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0018], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0423], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0271], device='cuda:0', requires_grad=True)\n",
      "3 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0001], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0011], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0536], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0402], device='cuda:0', requires_grad=True)\n",
      "4 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([7.1123e-06], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.7868e-06], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0642], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0507], device='cuda:0', requires_grad=True)\n",
      "5 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0008], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0035], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0691], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0590], device='cuda:0', requires_grad=True)\n",
      "6 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0024], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0010], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0745], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0700], device='cuda:0', requires_grad=True)\n",
      "7 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0026], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0024], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0803], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0766], device='cuda:0', requires_grad=True)\n",
      "8 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0018], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0036], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0861], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0918], device='cuda:0', requires_grad=True)\n",
      "9 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0030], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0023], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0910], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1004], device='cuda:0', requires_grad=True)\n",
      "10 -------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([-0.0022], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0041], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0955], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1086], device='cuda:0', requires_grad=True)\n",
      "11 -------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/quickdraw_sagan/gen_12.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-66f31e04bcc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdisc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSA_Discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/quickdraw_sagan/gen_{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/quickdraw_sagan/disc_{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/quickdraw_sagan/gen_12.pt'"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "with torch.no_grad():\n",
    "    real_imgs, cut_imgs, labels = next(iter(dataloader))\n",
    "    labels = labels.float()\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,3))\n",
    "    for i in range(5):\n",
    "        axes[i].imshow(real_imgs[i].view(256,256), cmap=\"Greys\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "    gen = nn.DataParallel(SA_Generator(imsize=256, F=64)).to(0)\n",
    "    disc = nn.DataParallel(SA_Discriminator(imsize=256, F=64)).to(0)\n",
    "    for i in range(1, 100, 1):\n",
    "        gen.load_state_dict(torch.load('models/quickdraw_sagan/gen_{}.pt'.format(i)))\n",
    "        gen.eval()\n",
    "        disc.load_state_dict(torch.load('models/quickdraw_sagan/disc_{}.pt'.format(i)))\n",
    "        disc.eval()\n",
    "    #     gen.apply(test_dropout)\n",
    "        print(gen.module.attention1.gamma)\n",
    "        print(gen.module.attention2.gamma)\n",
    "        print(disc.module.attention1.gamma)\n",
    "        print(disc.module.attention2.gamma)\n",
    "#         z = torch.rand(size=(len(real_imgs), 100))\n",
    "#         generated = gen(cut_imgs, labels, z)\n",
    "#         fig, axes = plt.subplots(2, 5, figsize=(10,3))\n",
    "#         for y in range(5):\n",
    "#             axes[0, y].imshow(cut_imgs[y].view(256,256).cpu().detach(), cmap=\"Greys\")\n",
    "#             axes[0, y].axis('off')\n",
    "#             axes[1, y].imshow(class_imgs[0 + y].view(28,28), cmap=\"Greys\")\n",
    "        #     axes[1, y].axis('off')\n",
    "#             axes[1, y].imshow(generated[y].cpu().detach().view(256,256), cmap=\"Greys\")\n",
    "#             axes[1, y].axis('off')\n",
    "    #         axes[1, y].set_title(labels[y].item())\n",
    "    #     print(disc(generated, labels).mean())\n",
    "        print(str(i) + ' -------------------------------------------')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
